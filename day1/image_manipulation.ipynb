{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_manipulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kreshuklab/teaching-dl-course-2019/blob/master/Webinars/exercise1/image_manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCfP8vqqAWNZ",
        "colab_type": "text"
      },
      "source": [
        "# Image Manipulation Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Q839jSD3MW",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We are going to work with Kaggle 2018 Data Science Bowl data.\n",
        "To start with go the [data webpage](https://www.kaggle.com/c/data-science-bowl-2018) and read the data description.\n",
        "\n",
        "Now let's download the data. To make it easier, we're going to work with a subset of it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z58CoLEBAPCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O66UElt2ZfhLXUKKX_nTxmIXh6fMA2rT' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1O66UElt2ZfhLXUKKX_nTxmIXh6fMA2rT\" -O kaggle_data.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UauJx3yE7TL",
        "colab_type": "text"
      },
      "source": [
        "Remember that you can execute any bash command from the Notebook if you preceed the command name with '!'.\n",
        "\n",
        "And please check whether the downloaded archive is around 80M (the value after the progress bar [ <=> ]). If the value is much smaller, rerun the previous cell - probably something failed. \n",
        "\n",
        "Those of you who like bash can play around with unzipping the data into nice folders. The rest of you can just run the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x2FqzdGE6ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq kaggle_data.zip && rm kaggle_data.zip && rm stage1_test.zip\n",
        "!mkdir nuclei_data && unzip -qq stage1_train.zip -d nuclei_data/ && rm stage1_train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vru7Pc7PFhHZ",
        "colab_type": "text"
      },
      "source": [
        "Don't forget that you can always check what is happening in your directory using `ls` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSIWiWwFtN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8FrTVajF5XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls nuclei_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht7KuL4TF9Fk",
        "colab_type": "text"
      },
      "source": [
        "Wow, that was a loooot of folders. Hint: you can clear the output of the cell by clicking the 'clear output' button below the 'run cell'.\n",
        "\n",
        "Now let's check what they contain by taking one random folder name:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgvaJ_AoGPNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls nuclei_data/eb1df8ed879d04b36980b0958a0e8fc446ad08c0bdcf3b5f42e3db023187c7e5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhHSytYNGXX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls nuclei_data/eb1df8ed879d04b36980b0958a0e8fc446ad08c0bdcf3b5f42e3db023187c7e5/images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-wQTTJdGdeU",
        "colab_type": "text"
      },
      "source": [
        "Okay, this one contains a png image. __TASK:__ Check other random folder names to make sure the structure is the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsC7r2AVH4oX",
        "colab_type": "text"
      },
      "source": [
        "## Displaying images\n",
        "\n",
        "Now we want to load some pictures and look at them. For this we would need the following libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIKaKom4NjJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we want to show images directly in the notebook\n",
        "%matplotlib inline\n",
        "import os       # to list folders content\n",
        "import numpy as np    # scientific computing \n",
        "import matplotlib.pyplot as plt   # plotting and visualisation\n",
        "import cv2    # computer vision library, works with images as numpy arrays\n",
        "from google.colab.patches import cv2_imshow   # the native cv2 function imshow doesn't work in google colab "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT2jCQQ4PLLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = 'nuclei_data/eb1df8ed879d04b36980b0958a0e8fc446ad08c0bdcf3b5f42e3db023187c7e5/images/eb1df8ed879d04b36980b0958a0e8fc446ad08c0bdcf3b5f42e3db023187c7e5.png'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA9B2Zw6Qpok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf--nJhSaHpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Another way to show loaded images that is more flexible than cv2_imshow is using plt from matplotlib\n",
        "plt.imshow(image)    # Hint: if you don't like the colormap change it by setting cmap to gray "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8qTyATgTR91",
        "colab_type": "text"
      },
      "source": [
        "If we want to have a better overview of what is happening in the folder, loading the images one by one is not the best approach. What we will do now is list all the folders we have, and write a function that will load an image file from a random folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euxX9HSNT5Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders_list = os.listdir('nuclei_data')  # get the list of all the folders inside nuclei_data\n",
        "folders_list[0]   # let's see how the folder names look like"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTQ2TzSUUwKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_random_image(directory):\n",
        "  rand_idx = np.random.randint(0, len(directory))   # get a random index\n",
        "  img_path = # TASK: what would be the image path here?\n",
        "  random_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "  cv2_imshow(random_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg3pT5bpVvXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now test your function and see how the images in your folder look like\n",
        "show_random_image(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M62IPj49YBlx",
        "colab_type": "text"
      },
      "source": [
        "## Operations on images\n",
        "\n",
        "Now let's look more into the operations that you can perform on your image. Firstly, let's write a function that visualises two images at the same time to examine the transformations visually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyuifTKyUDfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is something we would need matplotlib for\n",
        "def show_two_images(image1, image2):\n",
        "    f, axarr = plt.subplots(1, 2)   # we need two images in a row\n",
        "    axarr[0].imshow(image1, cmap='gray')\n",
        "    axarr[1].imshow(image2, cmap='gray')\n",
        "    _ = [ax.axis('off') for ax in axarr]   # remove the axis ticks\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bTDb9HAZY9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's check how this looks like\n",
        "show_two_images(image, image[:100, :100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okAFYEtzdWQe",
        "colab_type": "text"
      },
      "source": [
        "Looks fine. Now let's go through the transforms offered us by cv2 library.\n",
        "\n",
        "## Resizing image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rcyG_6aZcYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fx and fy are the scale factors along x and y axes \n",
        "resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
        "cv2_imshow(resized_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxzJDkeAfl3E",
        "colab_type": "text"
      },
      "source": [
        "TASK : try different way of [interpolation](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#cv.Resize). Which one looks better visually: nearest neighbor, bilinear or bicubic?\n",
        "Hint: use `show_two_images` function to visualise the difference. \n",
        "\n",
        "Advanced TASK: modify `show_two_images` to show n images - given a list of any number of images the function should plot all of them in a row. Visualise multiple interpolations at the same time.\n",
        "\n",
        "## Translating image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgDIwatCiu7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows,cols = image.shape\n",
        "# we need to define a transfromation matrix for translation\n",
        "# here we shift the image 100 pixels on the horizontal axis and 50 on vertical\n",
        "M = np.float32([[1, 0, 100],[0, 1, 50]])\n",
        "translated_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "show_two_images(image, translated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZKy6XpLjmhG",
        "colab_type": "text"
      },
      "source": [
        "## Rotating image \n",
        "\n",
        "TASK: follow the instructions [here](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#rotation) to rotate your image and visualise it.\n",
        "\n",
        "Advanced TASK: write a function that given an image and a number N will \n",
        "* rotate the image by a random angle in range (0, N) degrees\n",
        "* translate the image by a random number of pixels horizontally and vertically, where the number of pixels is not bigger than 1/N of image dimentions (e.g., for image shape = 100*200 and N = 2 the max translation is 50 and 100 pixels vertically and horizontally, respectively)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_aLh_37u15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here\n",
        "rotated_image = #  Your code here\n",
        "show_two_images(image, rotated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D9LG-xJ74nY",
        "colab_type": "text"
      },
      "source": [
        "## Affine Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXIbGjnR7H76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for the affine transformation we need to define three points \n",
        "# in the input image and their desired locations after the transformation\n",
        "points1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
        "points2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
        "\n",
        "M = cv2.getAffineTransform(points1, points2)\n",
        "\n",
        "affine_transformed_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "show_two_images(image, affine_transformed_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaZbAok--f2_",
        "colab_type": "text"
      },
      "source": [
        "TASK: flip your image using affine transformation. Note, that image.shape would show you the size as (rows, cols) while the points should be be provided in (cols, rows) format.\n",
        "\n",
        "Hint: for the points1 take the coordinates of the corner pixels. Where do you want these points to end up if you flip the image? \n",
        "\n",
        "Advanced TASK: apply Perspective Transformation on your image as described [here](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#perspective-transformation).\n",
        "\n",
        "## Thresholding image\n",
        "In simple cases you can get an object mask (segment your object) using plain thresholding. Let's see how good it works for our images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgUwmt1957vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pixels below the threshold (background) will be set to 0\n",
        "# pixels above or equal to the threshold (foreground) will be set to the given foreground value, typically 1\n",
        "threshold = 150\n",
        "foreground = 1 # value of foreground pixels in resulting binary image\n",
        "inverted_image = (image.max() - image) # in our example image the objects are dark, thus we invert before we threshold\n",
        "_, binary_thresholded_image = cv2.threshold(inverted_image, threshold, foreground, cv2.THRESH_BINARY)\n",
        "show_two_images(inverted_image, binary_thresholded_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dCojJG9Ij8X",
        "colab_type": "text"
      },
      "source": [
        "TASK: try different threshold values. Also compare it to [adaptive thresholding](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html#adaptive-thresholding). Which one seems to work better? Why? \n",
        "\n",
        "## Morphological Transformations\n",
        "The masks we got out of tresholding look suboptimal. There is noise, holes in the masks and some masks are merged together. We can try to alleviate there problems with such morphological transformations as opening - [errosion](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html#erosion) followed by [dilation](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html#dilation), and closing - dilation followed by errosion.\n",
        "\n",
        "Let's see how it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ7PUKl-jj12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to set a kernel\n",
        "# follow the links above to understand what the kernel does\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "opened_image = cv2.morphologyEx(binary_thresholded_image, cv2.MORPH_OPEN, kernel, iterations=3)\n",
        "show_two_images(binary_thresholded_image, opened_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo5VqIVomUbr",
        "colab_type": "text"
      },
      "source": [
        "TASK: try different kernel sizes and number of iterations. How does it affect the segmentation masks? \n",
        "\n",
        "Try closing (set the operation type to cv2.MORPH_CLOSE). Try different parameters as well.\n",
        "## Finding edges \n",
        "Image gradients can be used to detect object edges. Let's try to use the [Canny algorithm](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html#canny-edge-detection) from cv2 library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqioRxdMFJxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read more about minVal and maxVal arguments in the link above\n",
        "edges = cv2.Canny(image, 100, 150)\n",
        "show_two_images(image, edges)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxGsZ7hEnkm0",
        "colab_type": "text"
      },
      "source": [
        "TASK: try different minVal and maxVal. Does any combination give perfect object boundaries?\n",
        "\n",
        "Advanced TASK: segment the image with the watershed algorithm as described [here](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html#image-segmentation-with-watershed-algorithm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FArdMSFyoNR-",
        "colab_type": "text"
      },
      "source": [
        "## Further reading:\n",
        "Take a look at the [cv2 tutorials](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_table_of_contents_imgproc/py_table_of_contents_imgproc.html#image-processing-in-opencv) to find functions that might be useful for you. \n"
      ]
    }
  ]
}